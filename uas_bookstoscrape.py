# -*- coding: utf-8 -*-
"""UAS bookstoscrape.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mimcDUf1vn9XvBonfJa1pKwsvBFRY7ep
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.cluster import KMeans
from sklearn.metrics import mean_squared_error, r2_score

# Fungsi Scraping Data
def scrape_books():
    import requests
    from bs4 import BeautifulSoup

    base_url = "https://books.toscrape.com/catalogue/"
    start_url = "https://books.toscrape.com/catalogue/page-1.html"

    books_data = []
    max_books = 100

    while start_url and len(books_data) < max_books:
        response = requests.get(start_url)
        soup = BeautifulSoup(response.text, 'html.parser')

        for book in soup.find_all('article', class_='product_pod'):
            if len(books_data) >= max_books:
                break

            title = book.h3.a['title']
            price = book.find('p', class_='price_color').text[1:].replace('Â', '').strip()
            rating = book.p['class'][1]
            availability = book.find('p', class_='instock availability').text.strip()

            books_data.append({
                'Title': title,
                'Price': float(price.replace('£', '')),
                'Rating': rating,
                'Availability': availability
            })

        next_page = soup.find('li', class_='next')
        if next_page:
            next_url = next_page.a['href']
            start_url = base_url + next_url
        else:
            start_url = None

    return pd.DataFrame(books_data)

# Fungsi Preprocessing
def clean_and_preprocess_data(df):
    rating_mapping = {'One': 1, 'Two': 2, 'Three': 3, 'Four': 4, 'Five': 5}
    df['Rating'] = df['Rating'].map(rating_mapping)
    df.dropna(inplace=True)
    return df

# Fungsi untuk Unduh CSV
def download_csv(df):
    csv = df.to_csv(index=False)
    st.download_button(
        label="Unduh Hasil Scraping sebagai CSV",
        data=csv,
        file_name='books_data.csv',
        mime='text/csv',
    )

# Fungsi Visualisasi
def visualize_data(df):
    st.subheader("Distribusi Harga Buku")
    st.write("Grafik ini menunjukkan distribusi harga buku yang telah di-scrape.")
    fig, ax = plt.subplots()
    sns.histplot(df['Price'], bins=30, kde=True, ax=ax)
    st.pyplot(fig)

    st.subheader("Distribusi Rating Buku")
    st.write("Grafik ini menunjukkan distribusi rating buku dalam dataset.")
    fig, ax = plt.subplots()
    sns.countplot(x='Rating', data=df, palette='viridis', ax=ax)
    st.pyplot(fig)

# Fungsi Clustering
def perform_clustering(df):
    st.subheader("Clustering Buku Berdasarkan Harga dan Rating")
    st.write("Clustering ini membagi buku ke dalam 3 kelompok berdasarkan harga dan rating.")
    kmeans = KMeans(n_clusters=3, random_state=42)
    df['Cluster'] = kmeans.fit_predict(df[['Price', 'Rating']])
    fig, ax = plt.subplots()
    sns.scatterplot(x='Price', y='Rating', hue='Cluster', palette='viridis', data=df, ax=ax)
    st.pyplot(fig)

# Fungsi Regresi
def perform_regression(df):
    st.subheader("Regresi untuk Prediksi Harga Berdasarkan Rating")
    st.write("Model regresi digunakan untuk memprediksi harga buku berdasarkan rating.")
    X = df[['Rating']]
    y = df['Price']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    model = LinearRegression()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    st.write(f"Mean Squared Error: {mse:.2f}")
    st.write(f"R-squared: {r2:.2f}")

    fig, ax = plt.subplots()
    sns.scatterplot(x=y_test, y=y_pred, ax=ax)
    ax.set_xlabel('Actual Price')
    ax.set_ylabel('Predicted Price')
    st.pyplot(fig)

# Main Program
def main():
    st.title("Web scrapping kelompok 8")
    st.write("Aplikasi ini menyediakan dataset dan hasil analisa yang diambil dari website bookstoscrape.com")

    # Sidebar Menu
    st.sidebar.header("Navigasi")
    options = st.sidebar.radio("Pilih Langkah:", ["Scrape Data", "Visualisasi", "Algoritma 1: Clustering", "Algoritma 2: Regresi", "Kesimpulan"])

    if options == "Scrape Data":
        st.header("Scraping Data")
        df = scrape_books()
        st.dataframe(df.head())
        download_csv(df)
        st.write("Klik untuk mendownload dataset")

    elif options == "Visualisasi":
        st.header("Visualisasi Data")
        df = scrape_books()
        df = clean_and_preprocess_data(df)
        visualize_data(df)

    elif options == "Algoritma 1: Clustering":
        st.header("Algoritma 1: K-Means Clustering")
        df = scrape_books()
        df = clean_and_preprocess_data(df)
        perform_clustering(df)

    elif options == "Algoritma 2: Regresi":
        st.header("Algoritma 2: Regresi Linear")
        df = scrape_books()
        df = clean_and_preprocess_data(df)
        perform_regression(df)

    elif options == "Kesimpulan":
        st.header("Kesimpulan")
        st.write("Dataset buku menunjukkan distribusi harga dan rating yang dapat dikategorikan ke dalam klaster menggunakan K-Means.")
        st.write("Model regresi menunjukkan hubungan yang lemah antara rating dan harga buku, dengan R-squared rendah.")

if __name__ == "__main__":
    main()
